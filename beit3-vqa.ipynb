{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-01T16:31:16.697935Z",
     "iopub.status.busy": "2025-03-01T16:31:16.697499Z",
     "iopub.status.idle": "2025-03-01T16:31:16.703446Z",
     "shell.execute_reply": "2025-03-01T16:31:16.702426Z",
     "shell.execute_reply.started": "2025-03-01T16:31:16.697905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BeitModel, BertModel, BeitImageProcessor, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "import wandb\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"account_config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "wandb_key = config.get(\"wandb_key\")\n",
    "hf_token = config.get(\"hf_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T16:31:16.733368Z",
     "iopub.status.busy": "2025-03-01T16:31:16.732806Z",
     "iopub.status.idle": "2025-03-01T16:31:23.968105Z",
     "shell.execute_reply": "2025-03-01T16:31:23.966822Z",
     "shell.execute_reply.started": "2025-03-01T16:31:16.733326Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mppdddd00123\u001b[0m (\u001b[33mppddddpp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "wandb.login(key=\"65147faf3b81e0c1415dcd6fd695c6585a0535b9\")\n",
    "hf_token = \"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\"\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T16:31:23.970662Z",
     "iopub.status.busy": "2025-03-01T16:31:23.969730Z",
     "iopub.status.idle": "2025-03-01T16:31:23.975947Z",
     "shell.execute_reply": "2025-03-01T16:31:23.974711Z",
     "shell.execute_reply.started": "2025-03-01T16:31:23.970608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define paths\n",
    "IMAGE_FOLDER = \"/kaggle/input/vqa-dataset/vqa_dataset/images\"\n",
    "TRAIN_CSV = \"/kaggle/input/final-vqa-dataset/train.csv\"\n",
    "VAL_CSV = \"/kaggle/input/final-vqa-dataset/val.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T16:31:23.977969Z",
     "iopub.status.busy": "2025-03-01T16:31:23.977613Z",
     "iopub.status.idle": "2025-03-01T16:31:24.451652Z",
     "shell.execute_reply": "2025-03-01T16:31:24.450370Z",
     "shell.execute_reply.started": "2025-03-01T16:31:23.977939Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df\n",
    "\n",
    "train_df = load_data(TRAIN_CSV)\n",
    "val_df = load_data(VAL_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T16:31:24.454072Z",
     "iopub.status.busy": "2025-03-01T16:31:24.453745Z",
     "iopub.status.idle": "2025-03-01T16:31:30.893314Z",
     "shell.execute_reply": "2025-03-01T16:31:30.892084Z",
     "shell.execute_reply.started": "2025-03-01T16:31:24.454043Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2147d28f2a60418da71a8a45c9594fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8638a168113843f0996df2a1d0f892cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ff0cc3cfe147a48707bfb20c12faa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "982a7aa92efa46ae9bbf535c6e477c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c973e94674a541898c0c0855231c9da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/276 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py:165: UserWarning: The following named arguments are not valid for `BeitImageProcessor.__init__` and were ignored: 'feature_extractor_type'\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create answer vocabulary\n",
    "unique_answers = sorted(set(train_df[\"answer\"].tolist()))\n",
    "answer2id = {ans: i for i, ans in enumerate(unique_answers)}\n",
    "id2answer = {i: ans for i, ans in enumerate(unique_answers)}\n",
    "num_labels = len(answer2id)\n",
    "\n",
    "# Load BEiT-3 processor\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "image_processor = BeitImageProcessor.from_pretrained(\"microsoft/beit-base-patch16-224-pt22k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T16:31:30.895054Z",
     "iopub.status.busy": "2025-03-01T16:31:30.894671Z",
     "iopub.status.idle": "2025-03-01T16:31:30.903974Z",
     "shell.execute_reply": "2025-03-01T16:31:30.902922Z",
     "shell.execute_reply.started": "2025-03-01T16:31:30.895023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class VQADataset(Dataset):\n",
    "    def __init__(self, dataframe, image_processor, tokenizer, answer2id, base_image_dir):\n",
    "        self.data = dataframe\n",
    "        self.image_processor = image_processor\n",
    "        self.tokenizer = tokenizer\n",
    "        self.answer2id = answer2id\n",
    "        self.base_image_dir = base_image_dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # Extract category and image name from the image_path\n",
    "        image_path = row[\"image_path\"]\n",
    "        category, image_name = image_path.split('/')\n",
    "\n",
    "        full_image_path = os.path.join(self.base_image_dir, category, image_name)\n",
    "        \n",
    "        # Open the image\n",
    "        image = Image.open(full_image_path).convert(\"RGB\")\n",
    "        question = row[\"question\"]\n",
    "        answer = row[\"answer\"]\n",
    "        \n",
    "        # Process the image and question\n",
    "        image_tensor = self.image_processor(image, return_tensors=\"pt\")[\"pixel_values\"].squeeze(0)\n",
    "        question_tensor = self.tokenizer(question, padding=\"max_length\", truncation=True, max_length=50, return_tensors=\"pt\")\n",
    "        label = torch.tensor(self.answer2id.get(answer, 0), dtype=torch.long)\n",
    "        \n",
    "        return {\n",
    "            \"image\": image_tensor,\n",
    "            \"input_ids\": question_tensor[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": question_tensor[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": label,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T16:31:30.905387Z",
     "iopub.status.busy": "2025-03-01T16:31:30.905031Z",
     "iopub.status.idle": "2025-03-01T16:31:30.939115Z",
     "shell.execute_reply": "2025-03-01T16:31:30.936759Z",
     "shell.execute_reply.started": "2025-03-01T16:31:30.905340Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "dataset_train = VQADataset(train_df, image_processor, tokenizer, answer2id, IMAGE_FOLDER)\n",
    "dataset_val = VQADataset(val_df, image_processor, tokenizer, answer2id, IMAGE_FOLDER)\n",
    "train_loader = DataLoader(dataset_train, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T16:31:45.276500Z",
     "iopub.status.busy": "2025-03-01T16:31:45.276087Z",
     "iopub.status.idle": "2025-03-01T16:31:45.285468Z",
     "shell.execute_reply": "2025-03-01T16:31:45.283139Z",
     "shell.execute_reply.started": "2025-03-01T16:31:45.276455Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BEiTForVQA(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(BEiTForVQA, self).__init__()\n",
    "        self.beit = BeitModel.from_pretrained(\"microsoft/beit-base-patch16-224-pt22k\")\n",
    "        self.text_encoder = BertModel.from_pretrained(\"bert-base-uncased\")  # Use a transformer model for text encoding\n",
    "        self.image_encoder = nn.Linear(768, 512)\n",
    "        self.text_encoder_linear = nn.Linear(768, 512)  # Linear layer for text features after BERT\n",
    "        self.classifier = nn.Linear(512, num_labels)\n",
    "\n",
    "    def forward(self, image, input_ids, attention_mask):\n",
    "        image_features = self.beit(image).last_hidden_state[:, 0, :]  # Extract CLS token for image\n",
    "        text_outputs = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_features = text_outputs.last_hidden_state[:, 0, :]  # Extract CLS token for text\n",
    "        fusion = torch.relu(self.image_encoder(image_features) + self.text_encoder_linear(text_features))\n",
    "        logits = self.classifier(fusion)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T16:31:45.287382Z",
     "iopub.status.busy": "2025-03-01T16:31:45.286962Z",
     "iopub.status.idle": "2025-03-01T16:31:45.316231Z",
     "shell.execute_reply": "2025-03-01T16:31:45.314829Z",
     "shell.execute_reply.started": "2025-03-01T16:31:45.287340Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(model, train_loader, optimizer, criterion, scheduler, num_epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != \"label\"}\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            outputs = model(**inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "        wandb.log({\"train_loss\": total_loss / len(train_loader)})\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {total_loss/len(train_loader):.4f}\")\n",
    "        save_checkpoint(model, tokenizer, optimizer, scheduler, epoch)\n",
    "\n",
    "# Checkpoint functions\n",
    "def save_checkpoint(model, tokenizer, optimizer, scheduler, epoch, output_dir=\"/kaggle/working/beit3-vqa-checkpoints\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(output_dir, f\"checkpoint-epoch-{epoch}\")\n",
    "    model.save_pretrained(checkpoint_path)\n",
    "    tokenizer.save_pretrained(checkpoint_path)\n",
    "    torch.save(optimizer.state_dict(), os.path.join(checkpoint_path, \"optimizer.pt\"))\n",
    "    torch.save(scheduler.state_dict(), os.path.join(checkpoint_path, \"scheduler.pt\"))\n",
    "    print(f\"Checkpoint saved at {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T16:31:45.317798Z",
     "iopub.status.busy": "2025-03-01T16:31:45.317388Z",
     "iopub.status.idle": "2025-03-01T16:31:48.230651Z",
     "shell.execute_reply": "2025-03-01T16:31:48.229350Z",
     "shell.execute_reply.started": "2025-03-01T16:31:45.317741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BeitModel were not initialized from the model checkpoint at microsoft/beit-base-patch16-224-pt22k and are newly initialized: ['beit.pooler.layernorm.bias', 'beit.pooler.layernorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc1067347544bf9a71d10c9a1627efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ppddddpp/beit3-vqa/runs/ah108vtg?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7dcbd5a34400>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BEiTForVQA(num_labels).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * 3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "wandb.init(project=\"beit3-vqa\", name=\"beit3-vqa-run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T16:31:48.232210Z",
     "iopub.status.busy": "2025-03-01T16:31:48.231750Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   1%|          | 55/10331 [27:35<86:21:06, 30.25s/it, loss=2.25]/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Epoch 1/3:   1%|          | 56/10331 [28:06<86:15:10, 30.22s/it, loss=1.88]"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "train(model, train_loader, optimizer, criterion, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save final model\n",
    "final_model_path = \"/kaggle/working/beit3-vqa-model\"\n",
    "model.save_pretrained(final_model_path)\n",
    "tokenizer.save_pretrained(final_model_path)\n",
    "wandb.finish()\n",
    "print(\"Training complete and model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Push model to Hugging Face Hub\n",
    "HUGGINGFACE_MODEL_ID = \"ppdddd/beit3-vqa-finetuned\"\n",
    "login(token=os.getenv(\"HUGGINGFACE_TOKEN\"))\n",
    "model.push_to_hub(HUGGINGFACE_MODEL_ID,private=True)\n",
    "tokenizer.push_to_hub(HUGGINGFACE_MODEL_ID,private=True)\n",
    "print(f\"Model pushed to Hugging Face Hub: {HUGGINGFACE_MODEL_ID}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6632975,
     "sourceId": 10703026,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6733938,
     "sourceId": 10875334,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Columbina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
